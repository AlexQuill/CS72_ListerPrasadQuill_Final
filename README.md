# CS72_ListerPrasadQuill_Final

## Setup

## Project Description

Project Proposal 2
Aditya Prasad, Alex Quill, Sydney Lister
Spring 2021
COSC72


(1) Recap the idea you chose and summarize it. What are you going to do for the final project? Please provide a clear and concise explanation. 

For the final project, we plan to fine tune a text generator using different English rap artists to create artificial English rap music lyrics. We will compare the resulting generated lyrics to the original lyrics using by calculating their:
Syntactic complexity 
Lexical diversity
Rhyme density
We chose these metrics because it has been shown that they add to users’ perception of texts being authentic (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6804983/). 

The goal of this project would be to investigate whether certain rap artists are better/worse suited for artificial lyric generation. We can conclude that a rap artist is better/worse suited for artificial lyric generation if the lyrics generated by the model trained on their songs have syntactic complexity, lexical diversity, and rhyme density that are comparable to those of the artist’s authentic lyrics. If a rapper is “best suited for artificial lyric generation,” it does not mean that the model trained on their songs is the most syntactically complex, lexically diverse, and rhyme-dense - It means that their lyrics, when used as a training set for a text-generation model, produce an output that is most similar to the real lyrics of that artist, as measured by the above objective metrics. Simple lyrics should produce simple outputs, and complex lyrics should produce complex outputs. 

It should also be noted that, since we will be choosing which rap artists to compare, we introduce bias into our project. Thus, we cannot draw any definitive conclusions about all rappers. However, our aim to evaluate what rappers write lyrics that are “best suited” for authentic text generation is novel and relates to the more prescient NLP question of choosing the right kind of corpus for text generation. When training a text-generation model, it is important to choose a corpus that strikes the right balance between being too complex for a model to learn effectively from, and too simple to create convincing outputs. Our project aims to answer this question for a specific genre of music.

Thus, we cannot say that an artist who performs well by our chosen methods is best/worst suited for lyric generation, only that they fared better by our standards than the other chosen artists. 



(2) Explicitly mention the algorithm(s) that you will use in your final project (e.g. k-means clustering; fine-tuning a BERT classifier; CTC speech recognition; lexicon-based sentiment analysis; constructing intents, entities and dialog in the IBM Watson Chatbot; etc.) What kind of input does the algorithm require, and what kind of output does it produce? If you are using an algorithm that already exists as a Python package, provide at least one link that describes how you’ll implement it (e.g. a relevant page in the documentation of the package). If it does not exist as a Python package, provide links to at least two URLs that describe how you’ll use the algorithm. These can be pages from a tutorial in the website, from a third-party tutorial, or from a site like Stack Overflow.

We will be training a Long Short-Term Memory network to generate rap lyrics. We will train this LSTM model to operate at the word-level, i.e. output one word at a time. To do so, we will pass as input a sequence of words and the target will be the following word in the original text. The algorithm requires a sequence of vectorized representations of the words/strings instead of a sequence of words/strings to be passed as input. The vectorized representation will map each word to its frequency in the original corpus. During training, the model will output several generated sentences. We will use Tensorflow Keras Sequential() class to build our network(I). We use a character-level LSTM example (II) and word-level LSTM example (III) as the basis for our implementation. 

The final component of our project that will require an algorithm, should we choose to algorithmically evaluate these metrics, are syntactic complexity, lexical diversity, and rhyme density. Xiaofei Lu, a professor at Penn State University, published a web-based syntactic complexity analyzer in 2017 (IV). This analyzer measures up to 17 different components of syntactic complexity, including lexical variance, sentence coordination, and mean length of sentence (among many others). A number of online tools exist to evaluate rhyme density, including the public python function attached below (V), which we can use to evaluate real lyrics and those produced by our model. Finally, lexical diversity can be measured using the attached python library (VI). Each of these resources is explored in greater detail at the bottom of this file.

(https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)
(https://medium.com/@nithanth.ram/generating-song-lyrics-64d72f224635)
(https://medium.com/coinmonks/word-level-lstm-text-generator-creating-automatic-song-lyrics-with-neural-networks-b8a1617104fb) 
https://aihaiyang.com/software/l2sca/single/
https://gist.github.com/wezleysherman/8f3fe3cac7577855ad22fd9e023d15ed#file-rhyme_density-py 
https://pypi.org/project/lexical-diversity/

(3) What data are you going to use? (Explicitly mention the dataset, or the concrete method you will use to collect it with ample detail). Does your data need to be modified to be used with this algorithm?

We will use the following dataset to generate our corpus for this project: https://github.com/fpaupier/RapLyrics-Scraper. This dataset allows us to choose which artists we would like to get lyrics from. We are able to specify the number of songs we would like to scrape for each artist -- we might start with a small number of songs (5), evaluate performance, and increase this number if time permits. It should be noted that the songs will be chosen in decreasing order of popularity; the 5 songs chosen for each artist will be the 5 most popular of their songs. We need to convert all text into lowercase and remove punctuation. Then we will split our text into a list of tokens separated by spaces. We will then map each word to its frequency in the corpus. It should be noted that we are treating each artist’s lyrics as their own corpus, so word frequencies will be calculated with respect to only one artist’s corpus.  


Dataset: Genius API rap lyrics
What is it: Genius is a digital media website with a focus on Hip-Hop lyrics, annotations to songs, and other documents. The website is known for having a vast collection of lyrics, sorted by artist, genre, and even has user submitted annotations to these lyrics.
How to access: The attached link (https://github.com/fpaupier/RapLyrics-Scraper) is an open source scraper that allows us to filter the lyrics corpus by artist name and song popularity. 
Modified: As stated, we will need to convert text to lowercase, clean it (with respect to punctuation etc, perhaps retaining line endings), and tokenize the lyrics. Then we will process frequencies of words in the corpus, 
Lyric Scraper: https://github.com/fpaupier/RapLyrics-Scraper
Kaggle Article Contextualizing Its Usage:https://www.kaggle.com/rikdifos/rap-lyrics-text-mining 


(4) In the first part of the project you were asked a question about your metrics. (Essentially, how would you know that your project “works”). Expand on your previous answer. How can you measure the performance of your chosen algorithm? (For example, number of sentences parsed correctly, number of words with the correct POS tag, BLEU distances between a translated sentence and its target, etc.). How are you going to measure this number? Manually? Using an automated process to measure whether your tokens were right or wrong? You don’t need an automated process, but you do need to be clear about what you’ll do. Please provide clear examples of the process going from input, to output, to evaluation. Finally, if your project does not need metrics, then explain the hypothesis you’re working with and provide a description of how you’ll prove or disprove it. 


As mentioned in (1), we will be using the following metrics to evaluate performance of our LSTM models: 
Syntactic complexity: Can be measured using the package given from (http://www.personal.psu.edu/xxl13/downloads/l2sca.html). The package takes in plain text as input, and generates 14 indices of syntactic complexity: mean length of sentence (MLS), mean length of T-unit (MLT), mean length of clause (MLC), clauses per sentence (C/S), verb phrases per T-unit (VP/T), clauses per T-unit (C/T), dependent clauses per clause (DC/C), dependent clauses per T-unit (DC/T), T-units per sentence (T/S), complex T-unit ratio (CT/T), coordinate phrases per T-unit (CP/T), coordinate phrases per clause (CP/C), complex nominals per T-unit (CN/T), and complex nominals per clause (CN/C). We will compare the syntactic complexity of the generated lyrics to that of each song by the artist used for training the respective LSTM model. 
Lexical diversity: Can be measured using the package given from (https://pypi.org/project/lexical-diversity/). The package gives us a tokenize() function to tokenize the text. The documentation recommends we use the SpaCy part of speech sensitive lemmatizer to lemmatize the tokenized text. Then, we will call the ttr() function on the tokenized and lemmatized text to calculate lexical diversity. We will compare the lexical diversity of the generated lyrics to that of each song by the artist used for training the respective LSTM model. 
Rhyme density: Can be measured using the following implementation: https://gist.github.com/wezleysherman/8f3fe3cac7577855ad22fd9e023d15ed#file-rhyme_density-py . This function finds the number of rhymed syllables and divides it by the total number of syllables. We will compare the rhyme density of the generated lyrics to that of each song by the artist used for training the respective LSTM model. 



We will keep a separate file/repository of individual rapper performance metrics, as well as the model parameters, batch size, and evaluation metrics for each individual lyric output. 
